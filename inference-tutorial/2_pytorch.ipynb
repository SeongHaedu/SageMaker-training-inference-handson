{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9569dfd9",
   "metadata": {},
   "source": [
    "# ã‚¿ã‚¤ãƒˆãƒ«: SageMaker Inference (Endpoint) ã§ä»®æƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã‚ˆã†ğŸ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b2bbf-3218-4793-88be-b884c84eeef0",
   "metadata": {},
   "source": [
    "â–  æœ¬ãƒãƒ³ã‚ºã‚ªãƒ³ã®ã‚¹ã‚³ãƒ¼ãƒ—\n",
    "\n",
    "* ä»¥ä¸‹ã®ã‚ˆã†ãª æ¨è«–ã‚³ãƒ¼ãƒ‰ã®ç†è§£\n",
    "---\n",
    "```\n",
    "import os\n",
    "def model_fn(model_dir):\n",
    "    with open(os.path.join(model_dir,'my_model.txt')) as f:\n",
    "        model = f.read()[:-1]\n",
    "    return model\n",
    "def predict_fn(input_data, model):\n",
    "    response = f'{model} for the {input_data}st time'\n",
    "    return response\n",
    "```\n",
    "---\n",
    "* ä»¥ä¸‹ã®ã‚ˆã†ãª SageMaker SDK ã®ã‚³ãƒ¼ãƒ‰ã®ç†è§£\n",
    "---\n",
    "```\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data=model_s3_uri,\n",
    "    role= role,\n",
    "    framework_version = '1.11.0',\n",
    "    py_version='py38',\n",
    "    entry_point='inference.py',\n",
    "    source_dir=f'./{source_dir}/'\n",
    ")\n",
    "pytorch_predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    enpoint_name=endpoint_name\n",
    ")\n",
    "```\n",
    "---\n",
    "* Inference endpoint ã®ä½œæˆã¨å‘¼ã³å‡ºã—ã®ãƒãƒ³ã‚ºã‚ªãƒ³\n",
    "\n",
    "â–  æœ¬ãƒãƒ³ã‚ºã‚ªãƒ³ã®ã‚¹ã‚³ãƒ¼ãƒ—å¤–\n",
    "* Inference Endpoint ä»¥å¤–ã® SageMaker ã®æ©Ÿèƒ½\n",
    "* å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ (æ™‚é–“ã®é–¢ä¿‚ä¸Šãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¯è¡Œã„ã¾ã›ã‚“ã€‚)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a1a62",
   "metadata": {},
   "source": [
    "# SageMaker Inference (Endpoint) - åº§å­¦ç·¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413695ad",
   "metadata": {},
   "source": [
    "## å…¨ä½“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸\n",
    "\n",
    "![inference-overview](./images/inference-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff836b66",
   "metadata": {},
   "source": [
    "## æ¨è«–ã‚³ãƒ¼ãƒ‰ã®ãŠä½œæ³•\n",
    "\n",
    "![code-rule-inference](./images/code-rule-inference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64597428",
   "metadata": {},
   "source": [
    "# SageMaker Inference (Endpoint) - ãƒãƒ³ã‚ºã‚ªãƒ³ç·¨\n",
    "[SageMaker PyTorch Container](https://github.com/aws/deep-learning-containers/tree/master/pytorch/inference/docker)  ã‚’ä½¿ç”¨ã—ã¾ã™ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05a97a",
   "metadata": {},
   "source": [
    "## æº–å‚™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d8f2d",
   "metadata": {},
   "source": [
    "### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€å®šæ•°ã®è¨­å®šã€boto3 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®šã€ãƒ­ãƒ¼ãƒ«ã®å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e75a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from typing import Final\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "import os, boto3, json, numpy as np\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "from uuid import uuid4\n",
    "smr_client:Final = boto3.client('sagemaker-runtime')\n",
    "sm_client:Final = boto3.client('sagemaker')\n",
    "s3_client:Final = boto3.client('s3')\n",
    "endpoint_inservice_waiter:Final = sm_client.get_waiter('endpoint_in_service')\n",
    "role: Final[str] = sagemaker.get_execution_role()\n",
    "region: Final[str] = sagemaker.Session().boto_region_name\n",
    "bucket: Final[str] = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f7d0d",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir: Final[str] = 'model'\n",
    "!if [ -d ./{model_dir} ]; then rm -rf ./{model_dir}/;fi\n",
    "!mkdir ./{model_dir}/\n",
    "\n",
    "source_dir: Final[str] = 'source'\n",
    "!if [ -d ./{source_dir} ]; then rm -rf ./{source_dir}/;fi\n",
    "!mkdir ./{source_dir}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab3d8a",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ç›¸å½“ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ `tar.gz` ã§å›ºã‚ã¦ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\n",
    "* SageMaker ã§æ¨è«–ã™ã‚‹å ´åˆã¯æ©Ÿæ¢°å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ã‚’ `model.tar.gz` ã«å›ºã‚ã¦ãŠãå¿…è¦ãŒã‚ã‚‹\n",
    "    * SageMaker Training ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ãŸå ´åˆã¯è‡ªå‹•ã§ tar.gz ã«ãªã‚‹ãŒã€ã“ã®ãƒãƒ³ã‚ºã‚ªãƒ³ã§ã¯ Training Job ã‚’ä½¿ã‚ãªã„ãŸã‚ã€æ‰‹å‹•ã§ tar.gz ã«å›ºã‚ã‚‹\n",
    "    * æ©Ÿæ¢°å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ã¨è¨€ã£ãŸãŒã€ç”¨æ„ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã€ãã®èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’è¡Œã†ã ã‘ãªã®ã§å¿…ãšã—ã‚‚æ©Ÿæ¢°å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹å¿…è¦ã¯ãªã„\n",
    "    * ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ Hello my great machine learning model ã¨æ›¸ã‹ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(`my_model.txt`)ã‚’ä½œæˆã—ã¦ã€`tar.gz` ã«å›ºã‚ã‚‹\n",
    "* `model.tar.gz` ã‚’æ¨è«–ç’°å¢ƒã§ä½¿ã†ã«ã¯äºˆã‚ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc97969",
   "metadata": {},
   "source": [
    "#### `my_model.txt` ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./{model_dir}/my_model.txt\n",
    "Hello my great machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9c52b",
   "metadata": {},
   "source": [
    "#### `my_model.txt` ã‚’ `model.tar.gz` ã«å›ºã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefcc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {model_dir}\n",
    "!tar zcvf model.tar.gz ./*\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cda830",
   "metadata": {},
   "source": [
    "#### `model.tar.gz` ã‚’ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634aeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s3_uri:Final[str] = sagemaker.session.Session().upload_data(\n",
    "    f'./{model_dir}/model.tar.gz',\n",
    "    key_prefix = 'hello_sagemaker_inference'\n",
    ")\n",
    "print(model_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b327c0c",
   "metadata": {},
   "source": [
    "### æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã™ã‚‹\n",
    "* æœ€ä½é™ `model_fn` ã¨ `predict_fn` ãŒå¿…è¦\n",
    "* `model_fn` ã¯ `model.tar.gz` ã«å›ºã‚ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‚³ãƒ¼ãƒ‰\n",
    "  * ç¬¬ä¸€å¼•æ•°ã« `model.tar.gz` ã‚’å±•é–‹ã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå…¥ã‚‹\n",
    "  * è¿”ã‚Šå€¤ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™ã¨ã€`predict_fn` ã®ç¬¬äºŒå¼•æ•°ã«å…¥ã‚Œã‚‰ã‚Œã‚‹\n",
    "* `predict_fn` ã¯æ¨è«–ã‚³ãƒ¼ãƒ‰\n",
    "  * ç¬¬ä¸€å¼•æ•°ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ(æ¨è«–ã—ãŸã„ãƒ‡ãƒ¼ã‚¿)ãŒå…¥ã‚‹\n",
    "  * ç¬¬äºŒå¼•æ•°ã« model_fn ã®è¿”ã‚Šå€¤ãŒå…¥ã‚‹\n",
    "  * æ¨è«–çµæœã‚’è¿”ã‚Šå€¤ã«å…¥ã‚Œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fe886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./{source_dir}/inference.py\n",
    "import os\n",
    "def model_fn(model_dir):\n",
    "    with open(os.path.join(model_dir,'my_model.txt')) as f:\n",
    "        model = f.read()[:-1] # æ”¹è¡Œã‚’é™¤å¤–\n",
    "    return model\n",
    "def predict_fn(input_data, model):\n",
    "    response = f'{model} for the {input_data}st time'\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b991cb5",
   "metadata": {},
   "source": [
    "## SageMaker SDK ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–\n",
    "### SageMaker SDK ã‚’ç”¨ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤\n",
    "SageMaker SDK ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã«ã¯ã€[Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model) ã‚¯ãƒ©ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚‹  \n",
    "ä»Šå›ã¯ AWS ãŒç®¡ç†ãƒ»å…¬é–‹ã—ã¦ã„ã‚‹ PyTorch ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã†ãŸã‚ã€`Model` ã‚’ç¶™æ‰¿ã—ãŸ [PyTorchModel](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#sagemaker.pytorch.model.PyTorchModel) ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã€‚  \n",
    "`PyTorchModel` ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ã¤ã‘ã‚‹ä»»æ„ã®åå‰ã€ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã® S3 ã® URIã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚„ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ¨è«–ã‚³ãƒ¼ãƒ‰ãªã©ã‚’æŒ‡å®šã™ã‚‹ã€‚\n",
    "PyTorchModel ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ãŸã‚‰ã€[deploy](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy) ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€‚ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã¨å°æ•°ã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã¤ã‘ã‚‹ä»»æ„ã®åå‰ã‚’è¨­å®šã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84481baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åå‰ã®è¨­å®š\n",
    "model_name: Final[str] = 'PyTorchModel'\n",
    "endpoint_name: Final[str] = model_name + 'Endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ³ãƒ†ãƒŠã®æŒ‡å®š\n",
    "pytorch_model = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data=model_s3_uri,\n",
    "    role= role,\n",
    "    framework_version = '1.11.0',\n",
    "    py_version='py38',\n",
    "    entry_point='inference.py',\n",
    "    source_dir=f'./{source_dir}/'\n",
    ")\n",
    "pytorch_predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    enpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pytorch_predictor.predict(1)\n",
    "print(response,type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03fc98",
   "metadata": {},
   "source": [
    "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã§ããŸãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãªãœã‹ numpy array ã§ã‚ã‚‹ã€‚  \n",
    "ç†ç”±ã¯ [PyTorchPredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#sagemaker.pytorch.model.PyTorchPredictor) ã« serializer , desirializer ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¨­å®šã•ã‚Œã¦ãŠã‚Šã€`predict` ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿(â†‘ã®ä¾‹ã§ã¯ int å‹ã®1)ã‚’ numpy array ã« Serialize ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã£ãŸå¾Œã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ numpy array ã« Desiarlize ã™ã‚‹ãŸã‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pytorch_predictor.serializer, pytorch_predictor.deserializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpointã¨ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤\n",
    "pytorch_predictor.delete_endpoint()\n",
    "pytorch_model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d03d68",
   "metadata": {},
   "source": [
    "## Boto3 ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–\n",
    "serializer/desirializer ã¯ SageMaker SDK ã®æ©Ÿèƒ½ã§ã€æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ç’°å¢ƒ(AWS Lambda ãªã©)ã«ã¯å…¥ã£ã¦ã„ãªã„ã“ã¨ãŒå¤šã„ï¼ˆboto3ã§ã‚„ã‚‹ã“ã¨ãŒå¤šã„ï¼‰ã€‚ã¾ãŸã€æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç«‹ã¡ä¸Šã’ã‚‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€éš›ã¯ SageMaker SDKã‚’ä½¿ã‚ãªã„ç’°å¢ƒã‚‚ã‚ã‚Šãˆã‚‹ã€‚  \n",
    "ä¸€é€£ã®æµã‚Œã‚’ Boto3 ã§å®Ÿè¡Œã—ã¦ã¿ã¦Serializer/DeserializerãŒç„¡ã„å ´åˆã®æŒ™å‹•ã‚’ç¢ºèªã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13730b45",
   "metadata": {},
   "source": [
    "### æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ model.tar.gz ã«å›ºã‚ã¦ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "* pytorch ã®å ´åˆã¯æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ model.tar.gz ã«å†…åŒ…ã™ã‚‹å¿…è¦ãŒã‚ã‚‹\n",
    "* SageMaker SDK ã§ã¯ `deploy` ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè¡Œæ™‚ã«è£å´ã§æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ `model.tar.gz` ã«å›ºã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã‚Œã¦ã„ãŸ\n",
    "* boto3 ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å ´åˆã¯æ‰‹å‹•ã§ `tar.gz` ã§å›ºã‚ã¦ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {model_dir}\n",
    "!rm model.tar.gz\n",
    "!cp ../{source_dir}/inference.py ./\n",
    "!tar zcvf model.tar.gz ./*\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_s3_uri:Final[str] = sagemaker.session.Session().upload_data(\n",
    "    f'./{model_dir}/model.tar.gz',\n",
    "    key_prefix = 'hello_sagemaker_inference'\n",
    ")\n",
    "print(source_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055aaab",
   "metadata": {},
   "source": [
    "### EndpointConfigName è¨­å®š\n",
    "SageMaker SDK ã§ã¯ `deploy` ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè¡Œæ™‚ã«è‡ªå‹•ã§ Model ã¨åŒã˜åå‰ã§ EndpointConfig ã‚’ä½œæˆã™ã‚‹ãŒã€Boto3 ã¯æ˜ç¤ºçš„ã«ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name: Final[str] = model_name + 'EndpointConfig'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fafe6",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ä½œæˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚³ãƒ³ãƒ•ã‚£ã‚°ä½œæˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆ\n",
    "1. [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model) ã§ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ç’°å¢ƒï¼ˆæ¨è«–ã‚³ãƒ¼ãƒ‰ã‚„ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã€ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼‰ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã—ãŸ Model ã‚’ä½œæˆã™ã‚‹\n",
    "2. [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) ã§ä½¿ç”¨ã™ã‚‹ Model ã‚„æ¨è«–ã«ä½¿ã†ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã€å°æ•°ãªã©ï¼‰ã‚„è² è·ã®é…åˆ†ã‚’è¨­å®šã™ã‚‹\n",
    "3. [create_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint) ã§ EndpointConfig ã§è¨­å®šã—ãŸå†…å®¹ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fe196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã® URI ã‚’å–å¾—\n",
    "container_image_uri: Final[str] = sagemaker.image_uris.retrieve(\n",
    "    \"pytorch\", \n",
    "    sagemaker.session.Session().boto_region_name, # ECR ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š\n",
    "    version='1.11.0', # SKLearn ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š\n",
    "    instance_type = 'ml.m5.large', # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®š\n",
    "    image_scope = 'inference' # æ¨è«–ã‚³ãƒ³ãƒ†ãƒŠã‚’æŒ‡å®š\n",
    ")\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a282306",
   "metadata": {},
   "source": [
    "create_endpoint ã¯éåŒæœŸ API ã§ã€ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ãŒè£å´ã§ã¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ã„ã‚‹ã€‚[endpoint_inservice_waiter.wait](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.get_waiter) ã§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†ã‚’å¾…ã¤ã“ã¨ãŒã§ãã‚‹ã€‚ï¼ˆæ•°åˆ†ã‹ã‹ã‚‹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ä½œæˆ\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "# EndpointConfig ä½œæˆ\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTrafic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.m5.large',\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "# Endpoint ä½œæˆ\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "# Endpoint ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤\n",
    "endpoint_inservice_waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={'Delay': 5,}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53a487",
   "metadata": {},
   "source": [
    "ä¸€èˆ¬çš„ãª`application/json`ã®ãƒ˜ãƒƒãƒ€ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ã¿ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22945c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Accept='application/json',\n",
    "    Body='1'\n",
    ")\n",
    "predictions = json.loads(response['Body'].read().decode('utf-8'))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8902dda",
   "metadata": {},
   "source": [
    "ãªãœã‹ torch tensor ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ãªãœï¼Ÿ  \n",
    "[default_input_fn](https://github.com/aws/sagemaker-scikit-learn-container/blob/7773e19bf0df6bdd65f10076ff7e8ecc1390cb9b/src/sagemaker_sklearn_container/handler_service.py#L47) ãŒå½±éŸ¿ã—ã¦ã„ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2853b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# default_input_fn ç¢ºèª\n",
    "!curl -s https://raw.githubusercontent.com/aws/deep-learning-containers/master/pytorch/inference/docker/build_artifacts/default_inference_handler.py | pygmentize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_input_fn ãŒå‘¼ã¶ decode ã®ç¢ºèª\n",
    "!curl -s https://raw.githubusercontent.com/aws/sagemaker-inference-toolkit/master/src/sagemaker_inference/decoder.py | pygmentize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fced00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_types ã®ç¢ºèª\n",
    "!curl -s https://raw.githubusercontent.com/aws/sagemaker-inference-toolkit/master/src/sagemaker_inference/content_types.py | pygmentize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83815b5",
   "metadata": {},
   "source": [
    "request header ãŒ `application/json` ã ã£ãŸã‚‰ `torch.FloatTensor(np.array(json.loads(input_data), dtype=None))` ã—ã¦ã„ãŸãŸã‚ã€å°æ•°ã® torch tensor ã«ãªã£ã¦ã„ãŸã€‚  \n",
    "ä¸Šè¨˜ã‚’è¸ã¾ãˆã€SageMaker SDK ã® [NumpySerializer](https://github.com/aws/sagemaker-python-sdk/blob/bd8ea409ae91b07ac148520f7631fba9feee0069/src/sagemaker/serializers.py#L148) ã® [_serialize_array()](https://github.com/aws/sagemaker-python-sdk/blob/bd8ea409ae91b07ac148520f7631fba9feee0069/src/sagemaker/serializers.py#L188) ç›¸å½“ã‚’æ‰‹å‹•ã§è¡Œã„ã€ãƒ˜ãƒƒãƒ€ `application/x-npy` ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ã¿ã‚‹ã¨ã€torch tensor ã«ãªã‚‰ãšã«æ¸ˆã‚€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BytesIO()\n",
    "np.save(buffer,np.array(1))\n",
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-npy',\n",
    "    Accept='application/json',\n",
    "    Body=buffer.getvalue(),\n",
    ")\n",
    "predictions = json.loads(response['Body'].read().decode('utf-8'))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d076b",
   "metadata": {},
   "source": [
    "### Model, EndpointConfig, Endpoint ã‚’å‰Šé™¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35234916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰Šé™¤ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…ã¤\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726507c",
   "metadata": {},
   "source": [
    "## å‰å‡¦ç†ã¨å¾Œå‡¦ç†ã®è¿½åŠ \n",
    "### å‰å‡¦ç†ã¨å¾Œå‡¦ç†ã®é–¢æ•°ä½œæˆ\n",
    "æ¨è«–ã‚³ãƒ¼ãƒ‰ã« `input_fn` ã¨ `output_fn` ã‚’è¨˜è¿°ã™ã‚‹ã¨ã€`default_input_fn` ã‚„ `default_output_fn` ã¯ä½¿ã‚ã‚Œãšã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½œæˆã—ãŸ input_fn ã‚„ output_fn ãŒä½¿ã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./{source_dir}/inference.py\n",
    "import os, json\n",
    "def model_fn(model_dir):\n",
    "    with open(os.path.join(model_dir,'my_model.txt')) as f:\n",
    "        hello = f.read()[:-1] # æ”¹è¡Œã‚’é™¤å¤–\n",
    "    return hello\n",
    "def input_fn(input_data, content_type):\n",
    "    if content_type == 'text/csv':\n",
    "        transformed_data = input_data.split(',')\n",
    "    else:\n",
    "        raise ValueError(f\"Illegal content type {content_type}. The only allowed content_type is text/csv\")\n",
    "    print(input_data,transformed_data)\n",
    "    return transformed_data\n",
    "def predict_fn(transformed_data, model):\n",
    "    prediction_list = []\n",
    "    for data in transformed_data:\n",
    "        if data[-1] == '1':\n",
    "            ordinal = f'{data}st'\n",
    "        elif data[-1] == '2':\n",
    "            ordinal = f'{data}nd'\n",
    "        elif data[-1] == '3':\n",
    "            ordinal = f'{data}rd'\n",
    "        else:\n",
    "            ordinal = f'{data}th'\n",
    "        prediction = f'{model} for the {ordinal} time'\n",
    "        prediction_list.append(prediction)\n",
    "    print(transformed_data,prediction_list)    \n",
    "    return prediction_list\n",
    "def output_fn(prediction_list, accept):\n",
    "    if accept == 'text/csv':    \n",
    "        response = ''\n",
    "        for prediction in prediction_list:\n",
    "            response += prediction + '\\n'\n",
    "        print(prediction_list,response)\n",
    "    else:\n",
    "        raise ValueError(f\"Illegal accept type {accept}. The only allowed accept type is text/csv\")\n",
    "    return response, accept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67a7c7",
   "metadata": {},
   "source": [
    "### å‰å‡¦ç†ã¨å¾Œå‡¦ç†ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¢ãƒ‡ãƒ«ã¨ä¸€ç·’ã« `model.tar.gz ` ã§å›ºã‚ã¦ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {model_dir}\n",
    "!rm model.tar.gz\n",
    "!cp ../{source_dir}/inference.py ./\n",
    "!tar zcvf model.tar.gz ./*\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_s3_uri:Final[str] = sagemaker.session.Session().upload_data(\n",
    "    f'./{model_dir}/model.tar.gz',\n",
    "    key_prefix = 'hello_sagemaker_inference'\n",
    ")\n",
    "print(source_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75daf66",
   "metadata": {},
   "source": [
    "### Model, EndpointConfig, Endpoint ã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ä½œæˆ\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "# EndpointConfig ä½œæˆ\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTrafic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.m5.large',\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "# Endpoint ä½œæˆ\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "# Endpoint ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤\n",
    "endpoint_inservice_waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={'Delay': 5,}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424402b",
   "metadata": {},
   "source": [
    "### æ¨è«–ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹\n",
    "![usecase-inference](./images/usecase-inference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab278e",
   "metadata": {},
   "source": [
    "### æ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee02ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='text/csv',\n",
    "    Accept='text/csv',\n",
    "    Body='1,2,3,10000'\n",
    ")\n",
    "predictions = response['Body'].read().decode('utf-8')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4138b",
   "metadata": {},
   "source": [
    "### Model, EndpointConfig, Endpoint ã‚’å‰Šé™¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce147d",
   "metadata": {},
   "source": [
    "## éåŒæœŸæ¨è«–\n",
    "* éåŒæœŸæ¨è«–ã¯æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚’ S3 ã«é…ç½®ã—ã€æ¨è«–ã™ã‚‹ã¨ãã¯ S3 ã®ã©ã“ã«æ¨è«–ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã®ã‹ã‚’å¼•æ•°ã«å…¥ã‚Œã‚‹\n",
    "* æ¨è«–çµæœã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ã‚‹ S3 ã® URI ã«æ ¼ç´ã•ã‚Œã‚‹ãŒã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã•ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã¯æ¨è«–çµæœãŒç½®ã‹ã‚Œã¦ã„ã‚‹ä¿è¨¼ã¯ãªãã€å‡¦ç†ãŒçµ‚ã‚ã‚Šæ¬¡ç¬¬é…ç½®ã•ã‚Œã‚‹\n",
    "* [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) ã® AsyncInferenceConfig å¼•æ•°ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§éåŒæœŸæ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒç«‹ã¡ä¸ŠãŒã‚‹\n",
    "\n",
    "### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83102c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ä½œæˆ\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "# EndpointConfig ä½œæˆ\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTrafic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.m5.large',\n",
    "        },\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/hello_sagemaker_inference/async_inference/output\"\n",
    "        },\n",
    "    }\n",
    ")\n",
    "# Endpoint ä½œæˆ\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "# Endpoint ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤\n",
    "endpoint_inservice_waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={'Delay': 5,}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317c598",
   "metadata": {},
   "source": [
    "### æ¨è«–ãƒ‡ãƒ¼ã‚¿ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: Final[str] = './input_data.csv'\n",
    "with open(input_data,'wt') as f:\n",
    "    f.write('2,3,4,1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35884254",
   "metadata": {},
   "source": [
    "### æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚’ S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_s3_uri:Final[str] = sagemaker.Session().upload_data(\n",
    "    './input_data.csv',\n",
    "    key_prefix = 'hello_sagemaker_inference/async_inference'\n",
    ")\n",
    "print(input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baaa9b1",
   "metadata": {},
   "source": [
    "### æ¨è«–ã¨æ¨è«–çµæœã‚’å–å¾—\n",
    "æ¨è«–ã«ã¯ [invoke_endpoint_async](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html#SageMakerRuntime.Client.invoke_endpoint_async) ã‚’ä½¿ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a753e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_data_s3_uri,\n",
    "    ContentType='text/csv',\n",
    "    Accept='text/csv',\n",
    ")\n",
    "output_s3_uri = response['OutputLocation']\n",
    "output_key = output_s3_uri.replace(f's3://{bucket}/','')\n",
    "while True:\n",
    "    result = s3_client.list_objects(Bucket=bucket, Prefix=output_key)\n",
    "    exists = True if \"Contents\" in result else False\n",
    "    if exists:\n",
    "        print('!')\n",
    "        obj = s3_client.get_object(Bucket=bucket, Key=output_key)\n",
    "        predictions = obj['Body'].read().decode()\n",
    "        print(predictions)\n",
    "        break\n",
    "    else:\n",
    "        print('.',end='')\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf50f5",
   "metadata": {},
   "source": [
    "### ãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599e237",
   "metadata": {},
   "source": [
    "## ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–\n",
    "* ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ã›ãšã€æ¨è«–ãŒç™ºç”Ÿã—ã¦ã„ã‚‹æ™‚é–“ã«å¯¾ã—ã¦èª²é‡‘ã™ã‚‹æ¨è«–æ–¹æ³•\n",
    "* ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–ã®æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç«‹ã¡ä¸Šã’æ–¹ã¯ [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config) ã® Variant å†…ã® ServerlessConfig ã§è¨­å®šã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d33b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ä½œæˆ\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "# EndpointConfig ä½œæˆ\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'ModelName': model_name,\n",
    "            'VariantName': 'AllTrafic',\n",
    "            'ServerlessConfig': { \n",
    "                'MemorySizeInMB': 1024, \n",
    "                'MaxConcurrency': 3\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "# Endpoint ä½œæˆ\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "# Endpoint ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤\n",
    "endpoint_inservice_waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={'Delay': 5,}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='text/csv',\n",
    "    Accept='text/csv',\n",
    "    Body='1,2,3,10000'\n",
    ")\n",
    "predictions = response['Body'].read().decode('utf-8')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9635941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44605ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ba936",
   "metadata": {},
   "source": [
    "## ãƒãƒƒãƒæ¨è«–\n",
    "* ãƒãƒƒãƒæ¨è«–ã¯æºœã¾ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã¦æ¨è«–ã™ã‚‹ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒè‰¯ã„æ–¹æ³•ã§ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æ±‚ã‚ã‚‰ã‚Œãªã„æ™‚ã«ä½¿ç”¨ã™ã‚‹\n",
    "* ãƒãƒƒãƒæ¨è«–ã¯ [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model) ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ãŸã‚ã¨ã€create_transform_job ã§ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆã—ã¦æ¨è«–ã‚’è¡Œã†\n",
    "* æ¨è«–çµæœã¯ S3 ã«å‡ºåŠ›ã•ã‚Œã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d4b46",
   "metadata": {},
   "source": [
    "### æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab7514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p batch\n",
    "batch_data_dir: Final[str] = './batch'\n",
    "input_data1: Final[str] = 'input_data1.csv'\n",
    "input_data2: Final[str] = './input_data2.csv'\n",
    "with open(os.path.join(batch_data_dir,input_data1),'wt') as f:\n",
    "    f.write('3,4,5,100')\n",
    "with open(os.path.join(batch_data_dir,input_data2),'wt') as f:\n",
    "    f.write('9,8,7,6,5')\n",
    "!aws s3 rm --recursive s3://{bucket}/{prefix}\n",
    "prefix:Final[str] = 'hello_sagemaker_inference/transform_job'\n",
    "input_prefix:Final[str] = prefix + '/input'\n",
    "output_prefix:Final[str] = prefix + '/output'\n",
    "input_data_s3_uri:Final[str] = sagemaker.Session().upload_data(batch_data_dir,key_prefix = input_prefix)\n",
    "print(input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16e668",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af27428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model ä½œæˆ\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbca45",
   "metadata": {},
   "source": [
    "### æ¨è«–ã‚¸ãƒ§ãƒ–ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_job_name: Final[str] = f'{model_name}TransformJob-{uuid4()}'\n",
    "print(transform_job_name)\n",
    "response = sm_client.create_transform_job(\n",
    "    TransformJobName=transform_job_name,\n",
    "    ModelName=model_name,\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': f's3://{bucket}/{input_prefix}'\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'text/csv',\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': f's3://{bucket}/{output_prefix}',\n",
    "        'Accept': 'text/csv',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.m5.large',\n",
    "        'InstanceCount': 1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd545a",
   "metadata": {},
   "source": [
    "### æ¨è«–çµæœã‚’å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if sm_client.describe_transform_job(TransformJobName=transform_job_name)['TransformJobStatus'] == 'Completed':\n",
    "        print('!')\n",
    "        for content in s3_client.list_objects_v2(Bucket=bucket,Prefix=output_prefix)['Contents']:\n",
    "            obj = s3_client.get_object(Bucket=bucket, Key=content['Key'])\n",
    "            predictions = obj['Body'].read().decode()\n",
    "            print(predictions)\n",
    "        break\n",
    "    else:\n",
    "        print('.',end='')\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88052c48",
   "metadata": {},
   "source": [
    "## å…¨ã¦å‰Šé™¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for endpoint in sm_client.list_endpoints()['Endpoints']:\n",
    "#     response = sm_client.delete_endpoint(EndpointName=endpoint['EndpointName'])\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for endpoint_config in sm_client.list_endpoint_configs()['EndpointConfigs']:\n",
    "#     response = sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config['EndpointConfigName'])\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf14cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in sm_client.list_models()['Models']:\n",
    "#     response = sm_client.delete_model(ModelName=model['ModelName'])\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b0e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
